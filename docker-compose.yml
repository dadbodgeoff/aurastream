# Aurastream - Full Stack Docker Compose
# Brings up: Backend API, Redis, Worker, Web Frontend

services:
  # =============================================================================
  # Backend Services
  # =============================================================================
  
  api:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8001:8000"
    environment:
      - APP_ENV=development
      - DEBUG=true
      - REDIS_URL=redis://redis:6379
      - PYTHONPATH=/app/backend
    env_file:
      - ./backend/.env
    volumes:
      - ./backend:/app/backend
    depends_on:
      redis:
        condition: service_healthy
    command: uvicorn api.main:app --host 0.0.0.0 --port 8000 --reload
    networks:
      - aurastream
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  redis:
    image: redis:7-alpine
    ports:
      - "6380:6379"
    volumes:
      - redis_data:/data
    networks:
      - aurastream
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      - APP_ENV=development
      - REDIS_URL=redis://redis:6379
      - PYTHONPATH=/app/backend
    env_file:
      - ./backend/.env
    volumes:
      - ./backend:/app/backend
    depends_on:
      redis:
        condition: service_healthy
    command: rq worker --url redis://redis:6379 generation
    networks:
      - aurastream
    restart: unless-stopped
    deploy:
      replicas: 4
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 128M

  # Twitch Generation Worker - Processes Twitch-specific asset generation jobs
  twitch-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      - APP_ENV=development
      - REDIS_URL=redis://redis:6379
      - PYTHONPATH=/app/backend
    env_file:
      - ./backend/.env
    volumes:
      - ./backend:/app/backend
    depends_on:
      redis:
        condition: service_healthy
    command: rq worker --url redis://redis:6379 twitch_generation
    networks:
      - aurastream
    restart: unless-stopped
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 128M

  # Creator Intel Worker (V1) - Pre-computes keywords, tags, titles, video ideas every 4 hours
  creator-intel-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      - APP_ENV=development
      - REDIS_URL=redis://redis:6379
      - PYTHONPATH=/app
    env_file:
      - ./backend/.env
    volumes:
      - ./backend:/app/backend
    depends_on:
      redis:
        condition: service_healthy
    command: python -m backend.workers.creator_intel_worker
    networks:
      - aurastream
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 128M

  # Head Orchestrator - Enterprise-grade orchestration of all 14 workers
  # Manages scheduling, health monitoring, anomaly detection, and score reporting
  head-orchestrator:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      - APP_ENV=development
      - REDIS_URL=redis://redis:6379
      - PYTHONPATH=/app
    env_file:
      - ./backend/.env
    volumes:
      - ./backend:/app/backend
    depends_on:
      redis:
        condition: service_healthy
    command: python -m backend.workers.orchestrator.orchestrator
    networks:
      - aurastream
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 64M

  # YouTube Worker - Fetches YouTube trending data every 30 minutes
  youtube-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      - APP_ENV=development
      - REDIS_URL=redis://redis:6379
      - PYTHONPATH=/app
    env_file:
      - ./backend/.env
    volumes:
      - ./backend:/app/backend
    depends_on:
      redis:
        condition: service_healthy
    command: python -m backend.workers.youtube_worker
    networks:
      - aurastream
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 64M

  # Playbook Worker - Generates algorithmic playbook reports every 4 hours
  playbook-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      - APP_ENV=development
      - REDIS_URL=redis://redis:6379
      - PYTHONPATH=/app
    env_file:
      - ./backend/.env
    volumes:
      - ./backend:/app/backend
    depends_on:
      redis:
        condition: service_healthy
    command: python -m backend.workers.playbook_worker
    networks:
      - aurastream
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 64M

  # Creator Intel V2 Orchestrator - Enterprise analytics with quota-aware collection
  # Runs 6 analyzers: ContentFormat, Description, Semantic, Regional, LiveStream, Channel
  # Manages YouTube API quota (10k units/day), tiered aggregation (Redis â†’ PostgreSQL)
  intel-v2-orchestrator:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      - APP_ENV=development
      - REDIS_URL=redis://redis:6379
      - PYTHONPATH=/app
    env_file:
      - ./backend/.env
    volumes:
      - ./backend:/app/backend
    depends_on:
      redis:
        condition: service_healthy
    command: python -m backend.workers.intel.cli start
    networks:
      - aurastream
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 128M

  # Twitch Streams Worker - Fetches Twitch stream data every 15 minutes for competition analysis
  twitch-streams-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      - APP_ENV=development
      - REDIS_URL=redis://redis:6379
      - PYTHONPATH=/app
    env_file:
      - ./backend/.env
    volumes:
      - ./backend:/app/backend
    depends_on:
      redis:
        condition: service_healthy
    command: python -m backend.workers.twitch_streams_worker
    networks:
      - aurastream
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 64M

  # Clip Radar Worker - Polls Twitch clips every 5 minutes for viral detection
  # NOTE: This is now also started automatically by the API server on startup.
  # This separate service is kept for production scaling and redundancy.
  clip-radar-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      - APP_ENV=development
      - REDIS_URL=redis://redis:6379
      - PYTHONPATH=/app
    env_file:
      - ./backend/.env
    volumes:
      - ./backend:/app/backend
    depends_on:
      redis:
        condition: service_healthy
      api:
        condition: service_healthy
    command: python -m backend.workers.clip_radar_worker
    networks:
      - aurastream
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 64M

  # Thumbnail Intel Worker - Analyzes YouTube gaming thumbnails daily at 6 AM EST
  # Uses Gemini Vision for layout/design analysis
  thumbnail-intel-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      - APP_ENV=development
      - REDIS_URL=redis://redis:6379
      - PYTHONPATH=/app
    env_file:
      - ./backend/.env
    volumes:
      - ./backend:/app/backend
    depends_on:
      redis:
        condition: service_healthy
    command: python -m backend.workers.thumbnail_intel_worker
    networks:
      - aurastream
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 64M

  # Alert Animation Worker - Processes depth map generation and animation exports
  # Uses Depth Anything V2 for depth maps, FFmpeg for server-side exports
  alert-animation-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      - APP_ENV=development
      - REDIS_URL=redis://redis:6379
      - PYTHONPATH=/app/backend
      - HF_HOME=/app/.cache/huggingface
      - TRANSFORMERS_CACHE=/app/.cache/huggingface
    env_file:
      - ./backend/.env
    volumes:
      - ./backend:/app/backend
      - alert-animation-cache:/app/.cache
    depends_on:
      redis:
        condition: service_healthy
    command: rq worker --url redis://redis:6379 alert_animation
    networks:
      - aurastream
    restart: unless-stopped
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 1536M
        reservations:
          memory: 512M

  # =============================================================================
  # Frontend Services
  # =============================================================================
  
  web:
    build:
      context: ./tsx
      dockerfile: apps/web/Dockerfile
      target: dev
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=development
      - NEXT_PUBLIC_API_URL=http://localhost:8001
      - WATCHPACK_POLLING=true
    volumes:
      # Mount source files for hot reload, but preserve container's node_modules
      - ./tsx/apps/web/src:/app/apps/web/src
      - ./tsx/apps/web/public:/app/apps/web/public
      - ./tsx/packages/ui/src:/app/packages/ui/src
      - ./tsx/packages/shared/src:/app/packages/shared/src
      - ./tsx/packages/api-client/src:/app/packages/api-client/src
    depends_on:
      api:
        condition: service_healthy
    networks:
      - aurastream
    restart: unless-stopped

networks:
  aurastream:
    driver: bridge

volumes:
  redis_data:
  alert-animation-cache:

# =============================================================================
# E2E Validation (Optional - run with: docker compose run e2e-validate)
# =============================================================================
# 
# To validate the stack after startup:
#   docker compose run --rm e2e-validate
#
# Or use the local script:
#   ./scripts/validate-startup.sh
#
